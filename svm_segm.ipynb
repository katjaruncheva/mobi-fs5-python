{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Bonus Tasks](svm_segm.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.ndimage as ndi\n",
    "import skimage.morphology as morph\n",
    "import skimage.util\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_result(img, seg, border_radius=1, interior_opacity=1, interior_opacity_decay=0.9, color=(0,1,0)):\n",
    "    img  = np.dstack([img] * 3).copy()\n",
    "    img -= img.min()\n",
    "    img /= img.max()\n",
    "    selem  = morph.disk(border_radius)\n",
    "    seg_bd = np.logical_xor(morph.binary_dilation(seg, selem), morph.binary_erosion(seg, selem))\n",
    "    mask_decay = ndi.distance_transform_edt(seg)\n",
    "    for i in range(3):\n",
    "        opacity = interior_opacity / pow(1 + mask_decay[seg], interior_opacity_decay)\n",
    "        img[:,:,i][seg] = color[i] * opacity + (1 - opacity) * img[:,:,i][seg]\n",
    "        img[:,:,i][seg_bd] = color[i]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_sizes = (32, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**[Task 1.1.]()** Implement `create_data_matrix`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_matrix(img, patch_sizes):\n",
    "    #Step 1: creating nonoverlapping patches\n",
    "    patches=skimage.util.view_as_blocks(img, patch_sizes)\n",
    "\n",
    "    #Step 2: Flatten each block und reshape the output into 2D matrix\n",
    "    num_patches= patches.shape[0] * patches.shape [1] #number of patches\n",
    "    patch_height, patch_width = patch_sizes\n",
    "\n",
    "    #Flatten the patches and reshape into a 2D matrix\n",
    "    X = patches.reshape (num_patches, patch_height * patch_width)\n",
    "    return X\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task 1.2.]()** Implement `create_gt_labels_vector`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gt_labels_vector(gt_img, patch_sizes):\n",
    "    # Step 1: Create non-overlapping patches\n",
    "    patches = skimage.util.view_as_blocks(gt_img, block_shape=patch_sizes)\n",
    "\n",
    "    # Step 2: Flatten patches and compute labels\n",
    "    num_patches_y, num_patches_x, patch_height, patch_width = patches.shape\n",
    "\n",
    "    # Flatten the patches and calculate the labels\n",
    "    labels = np.zeros(num_patches_y * num_patches_x, dtype=int)\n",
    "\n",
    "    # Iterate through the patches and calculate the label for each patch\n",
    "    for i in range(num_patches_y):\n",
    "        for j in range(num_patches_x):\n",
    "            patch = patches[i, j]\n",
    "            # Calculate the percentage of foreground pixels\n",
    "            foreground_percentage = np.sum(patch) / (patch_height * patch_width)\n",
    "            \n",
    "            # Assign the label based on the percentage of foreground\n",
    "            if foreground_percentage > 0.5:\n",
    "                labels[i * num_patches_x + j] = 1  # More than 50% foreground\n",
    "            elif foreground_percentage == 0:\n",
    "                labels[i * num_patches_x + j] = -1  # No foreground\n",
    "            else:\n",
    "                labels[i * num_patches_x + j] = 0  # Mixed foreground and background\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task 1.3.]()** Create the SVM classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(class_weight='balanced', gamma=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task 1.3 (a).]()** Create the data matrices for the images `dna-33` and `dna-44`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_33 = plt.imread(\"data/NIH3T3/gt/33.png\")\n",
    "img_44 = plt.imread(\"data/NIH3T3/gt/44.png\")\n",
    "img_33_dm = create_data_matrix(img_33, patch_sizes)\n",
    "img_44_dm = create_data_matrix(img_44, patch_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task 1.3 (b).]()** Create the corresponding ground truth label vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_33_labels = create_gt_labels_vector(img_33, patch_sizes)\n",
    "img_44_labels = create_gt_labels_vector(img_44, patch_sizes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task 1.3 (c).]()** Create the *combined* data matrices and ground truth label vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of stacked data matrix: (2109, 1024)\n",
      "Shape of stacked label vector: (2109,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def stack_data_matrices_and_labels(img_33_dm, img_33_labels, img_44_dm, img_44_labels):\n",
    "    # Concatenate data matrices along axis 0 (rows)\n",
    "    X_stacked = np.concatenate((img_33_dm, img_44_dm), axis=0)\n",
    "    \n",
    "    # Concatenate label vectors along axis 0 (rows)\n",
    "    y_stacked = np.concatenate((img_33_labels, img_44_labels), axis=0)\n",
    "    \n",
    "    return X_stacked, y_stacked\n",
    "\n",
    "    \n",
    "print(\"Shape of stacked data matrix:\", X_stacked.shape)\n",
    "print(\"Shape of stacked label vector:\", y_stacked.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task 1.3 (d).]()** Train the classifier using the data matrix and label vectors from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_trained=clf.fit(X_stacked, y_stacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task 1.4.]()** Implement the function `predict_image`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img):\n",
    "    # Step 1: Use create_data_matrix to get the data matrix for the image\n",
    "    X = create_data_matrix(img, patch_sizes)\n",
    "    \n",
    "    # Step 2: Predict the labels for each patch using the trained classifier\n",
    "    predicted_labels = clf.predict(X)\n",
    "    \n",
    "    # Step 3: Create the binary result image\n",
    "    # Calculate the number of patches along x and y axes\n",
    "    num_patches_y = img.shape[0] // patch_sizes[0]  # Number of patches in height\n",
    "    num_patches_x = img.shape[1] // patch_sizes[1]  # Number of patches in width\n",
    "    \n",
    "   # Step 4: Reshape predicted_labels into a 2D array corresponding to patches in the image\n",
    "    predicted_labels_reshaped = predicted_labels.reshape(num_patches_y, num_patches_x)\n",
    "    \n",
    "    # Step 5: Create a binary result image: True for foreground patches, False otherwise\n",
    "    result = predicted_labels_reshaped == 1  # Set foreground patches as True, background as False\n",
    "    \n",
    "    # Step 6: Return the result as a binary image\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 1024 but corresponding boolean dimension is 32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m seg \u001b[38;5;241m=\u001b[39m predict_image(img)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m----> 5\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mblend_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseg\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m, in \u001b[0;36mblend_result\u001b[0;34m(img, seg, border_radius, interior_opacity, interior_opacity_decay, color)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m      9\u001b[0m     opacity \u001b[38;5;241m=\u001b[39m interior_opacity \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mpow\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m mask_decay[seg], interior_opacity_decay)\n\u001b[0;32m---> 10\u001b[0m     img[:,:,i][seg] \u001b[38;5;241m=\u001b[39m color[i] \u001b[38;5;241m*\u001b[39m opacity \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m opacity) \u001b[38;5;241m*\u001b[39m \u001b[43mimg\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseg\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m     img[:,:,i][seg_bd] \u001b[38;5;241m=\u001b[39m color[i]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 1024 but corresponding boolean dimension is 32"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = plt.imread(f'data/NIH3T3/im/dna-0.png')\n",
    "seg = predict_image(img)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(blend_result(img, seg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task 1.5.]()** Perform batch processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
